# Guia de Uso do Apache Airflow - Tech Minds Analytics

## üìã Vis√£o Geral

O Apache Airflow orquestra o pipeline ETL automaticamente, executando as camadas Bronze ‚Üí Silver ‚Üí Gold de forma sequencial e monitorada.

---

## üöÄ Primeiro Acesso

### 1. Acessar a Interface Web

```
URL: http://localhost:8080
Usu√°rio: admin
Senha: admin
```

### 2. Localizar a DAG

Na p√°gina principal, procure por:
```
DAG Name: mental_health_etl_pipeline
Tags: etl, mental-health, data-lake
```

### 3. Ativar a DAG

- Clique no toggle √† esquerda do nome da DAG para ativ√°-la
- Status mudar√° de **OFF** para **ON**

---

## üîÑ Executar o Pipeline

### Execu√ß√£o Manual (Trigger)

1. Clique no nome da DAG `mental_health_etl_pipeline`
2. No canto superior direito, clique no bot√£o **‚ñ∂ Trigger DAG**
3. (Opcional) Adicione configura√ß√µes customizadas
4. Clique em **Trigger**

### Execu√ß√£o Agendada

A DAG est√° configurada para executar automaticamente **diariamente** (`@daily`).

Para alterar o schedule:
```python
# Em airflow/dags/mental_health_etl_dag.py
schedule_interval='@daily'  # Op√ß√µes: @hourly, @weekly, @monthly, cron expression
```

---

## üìä Monitorar Execu√ß√£o

### Visualizar o Graph

1. Acesse a DAG
2. Clique na aba **Graph**
3. Veja o fluxo visual das tasks:

```
initialize_minio ‚Üí bronze_layer ‚Üí silver_layer ‚Üí gold_layer ‚Üí validate_pipeline ‚Üí notify_completion
```

**Cores das Tasks:**
- üü¢ Verde escuro: Sucesso
- üî¥ Vermelho: Falha
- üü° Amarelo: Em execu√ß√£o
- ‚ö™ Cinza: Aguardando

### Visualizar Logs

1. Clique em qualquer task no graph
2. Selecione **Log**
3. Veja a sa√≠da detalhada da execu√ß√£o

**Exemplo de log esperado:**
```
[2025-11-26 10:00:00] INFO - üîß Inicializando MinIO...
[2025-11-26 10:00:01] INFO - ‚úÖ Bucket 'bronze' criado com sucesso
[2025-11-26 10:00:01] INFO - ‚úÖ MinIO inicializado com sucesso!
```

---

## üéØ Estrutura da DAG

### Tasks Implementadas

| Task ID | Descri√ß√£o | Tempo Estimado |
|---------|-----------|----------------|
| `initialize_minio` | Cria buckets no MinIO | ~2s |
| `bronze_layer` | Ingere dados brutos | ~5s |
| `silver_layer` | Limpa e padroniza dados | ~10s |
| `gold_layer` | Gera agrega√ß√µes | ~5s |
| `validate_pipeline` | Valida dados processados | ~3s |
| `notify_completion` | Notifica conclus√£o | ~1s |

**Tempo Total:** ~26 segundos

### Depend√™ncias (Order)

```python
initialize_minio >> bronze_layer >> silver_layer >> gold_layer >> validate_pipeline >> notify_completion
```

---

## ‚öôÔ∏è Configura√ß√µes Avan√ßadas

### Alterar Schedule

```python
# @daily - Todo dia √† meia-noite
# @hourly - A cada hora
# @weekly - Toda segunda-feira √† meia-noite
# @monthly - Todo dia 1¬∫ do m√™s
# Cron: '0 9 * * *' - Todo dia √†s 9h
```

### Configurar Retries

```python
default_args = {
    'retries': 2,              # N√∫mero de tentativas
    'retry_delay': timedelta(minutes=5),  # Intervalo entre tentativas
}
```

### Notifica√ß√µes por Email

```python
default_args = {
    'email_on_failure': True,
    'email_on_retry': True,
    'email': ['seu-email@example.com'],
}
```

(Requer configura√ß√£o de SMTP no Airflow)

---

## üõ†Ô∏è Troubleshooting

### DAG n√£o aparece na interface

**Problema:** DAG n√£o est√° sendo detectada

**Solu√ß√£o:**
```bash
# 1. Verifique se o arquivo est√° no diret√≥rio correto
ls airflow/dags/

# 2. Restart do Airflow Scheduler
docker-compose restart airflow-scheduler

# 3. Verifique logs de erros
docker-compose logs airflow-scheduler | grep ERROR
```

### Task falhando repetidamente

**Problema:** Uma task espec√≠fica est√° falhando

**Passos:**
1. Clique na task no Graph
2. Selecione **Log**
3. Identifique a mensagem de erro
4. Verifique:
   - MinIO est√° rodando?
   - Arquivo CSV existe em `datasets/`?
   - Vari√°veis de ambiente est√£o corretas?

**Comandos √∫teis:**
```bash
# Verificar status dos containers
docker-compose ps

# Logs do MinIO
docker-compose logs minio

# Logs do Airflow Scheduler
docker-compose logs -f airflow-scheduler
```

### Limpar hist√≥rico de execu√ß√µes

```bash
# Via UI do Airflow:
# 1. V√° em Admin ‚Üí DAGs
# 2. Selecione a DAG
# 3. Actions ‚Üí Delete

# Via CLI (dentro do container):
docker exec -it tech-minds-airflow-scheduler airflow dags delete mental_health_etl_pipeline
```

---

## üìà Boas Pr√°ticas

### 1. Teste Local Primeiro

Antes de executar via Airflow, teste o ETL standalone:
```bash
python src/etl.py
```

### 2. Use Logs Detalhados

Todas as fun√ß√µes do ETL j√° t√™m logging integrado. Consulte os logs no Airflow UI.

### 3. Valide Dados Regularmente

A task `validate_pipeline` verifica automaticamente:
- ‚úÖ Buckets existem
- ‚úÖ Arquivos foram criados
- ‚úÖ Dados est√£o corretos

### 4. Monitore Execu√ß√µes

- Acesse regularmente a UI do Airflow
- Verifique o hist√≥rico na aba **Tree**
- Configure alertas para falhas

---

## üîÑ Fluxo Completo Recomendado

```bash
# 1. Subir infraestrutura
cd infra
docker-compose up -d

# 2. Aguardar inicializa√ß√£o (2-3 minutos)
docker-compose logs -f airflow-init

# 3. Acessar Airflow UI
# Navegador: http://localhost:8080
# Login: admin / admin

# 4. Ativar a DAG
# Toggle ON na interface

# 5. Executar (trigger manual ou aguardar schedule)
# Bot√£o "Trigger DAG"

# 6. Monitorar execu√ß√£o
# Aba "Graph" ‚Üí Acompanhar tasks

# 7. Validar resultados
# MinIO Console: http://localhost:9001
# Verificar buckets: bronze, silver, gold

# 8. Visualizar dados
# Metabase: http://localhost:3000
# Jupyter: jupyter notebook notebooks/01_exploratory_analysis.ipynb
```

---

## üìö Recursos Adicionais

### Documenta√ß√£o Oficial
- [Apache Airflow Docs](https://airflow.apache.org/docs/)
- [Airflow DAGs](https://airflow.apache.org/docs/apache-airflow/stable/concepts/dags.html)

### Comandos √öteis

```bash
# Parar todos os servi√ßos
docker-compose down

# Parar e remover volumes (reset completo)
docker-compose down -v

# Ver logs em tempo real
docker-compose logs -f

# Restart de um servi√ßo espec√≠fico
docker-compose restart airflow-webserver

# Acessar shell do Airflow
docker exec -it tech-minds-airflow-webserver bash
```

---

**√öltima atualiza√ß√£o:** Novembro 2025
